{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util import get_range, normalize\n",
    "from pt_dataset import PTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (5500, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>A32</th>\n",
       "      <th>A33</th>\n",
       "      <th>A34</th>\n",
       "      <th>A35</th>\n",
       "      <th>A36</th>\n",
       "      <th>A37</th>\n",
       "      <th>A38</th>\n",
       "      <th>A39</th>\n",
       "      <th>A40</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.223</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>-0.547</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.410</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-1.013</td>\n",
       "      <td>-0.895</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.770</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-1.013</td>\n",
       "      <td>-0.748</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.107</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>-0.629</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>-0.681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.270</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>-0.619</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>-0.705</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829</td>\n",
       "      <td>-0.719</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-0.617</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.693</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.331</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.498</td>\n",
       "      <td>-0.361</td>\n",
       "      <td>-0.857</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.496</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>-0.784</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.578</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1     A2     A3     A4     A5     A6     A7     A8     A9    A10  ...  \\\n",
       "0 -1.223 -0.798 -0.867 -0.639 -0.545 -0.412 -0.795 -0.629 -0.547 -0.868  ...   \n",
       "1 -1.410 -1.029 -1.013 -0.895 -0.762 -0.676 -1.043 -0.851 -0.775 -1.037  ...   \n",
       "2 -1.107 -0.649 -0.629 -0.492 -0.367 -0.298 -0.682 -0.478 -0.395 -0.681  ...   \n",
       "3 -1.270 -0.855 -0.958 -0.707 -0.619 -0.469 -0.872 -0.705 -0.620 -0.988  ...   \n",
       "4 -1.331 -0.862 -0.761 -0.689 -0.498 -0.361 -0.857 -0.600 -0.496 -0.779  ...   \n",
       "\n",
       "     A32    A33    A34    A35    A36    A37    A38    A39    A40  Class  \n",
       "0 -0.766 -0.555 -0.714 -0.545 -0.587 -0.871 -0.620 -0.568 -0.607      0  \n",
       "1 -0.919 -0.770 -0.847 -0.663 -0.723 -1.013 -0.748 -0.698 -0.817      0  \n",
       "2 -0.692 -0.445 -0.588 -0.371 -0.368 -0.746 -0.457 -0.379 -0.469      0  \n",
       "3 -0.829 -0.719 -0.774 -0.617 -0.688 -0.937 -0.693 -0.657 -0.779      0  \n",
       "4 -0.861 -0.571 -0.784 -0.545 -0.562 -0.952 -0.642 -0.578 -0.648      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_INDEX = 3\n",
    "files = [\n",
    "    os.path.join('data', 'banknote_preprocessed.csv'),\n",
    "    os.path.join('data', 'htru2_preprocessed.csv'),\n",
    "    os.path.join('data', 'segment_preprocessed.csv'),\n",
    "    os.path.join('data', 'texture_preprocessed.csv'),\n",
    "]\n",
    "file_path = files[DATA_INDEX]\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "print('Data:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5500, 40)\n",
      "y: (5500,)\n",
      "features: 40, classes: 11\n"
     ]
    }
   ],
   "source": [
    "y = df['Class'].to_numpy().astype(np.long)\n",
    "X = df.drop(['Class'], axis=1).to_numpy().astype(np.float32)\n",
    "n_features = X.shape[1]\n",
    "n_classes = len(np.unique(y))\n",
    "print('X:', X.shape)\n",
    "print('y:', y.shape)\n",
    "print('features: {}, classes: {}'.format(n_features, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_test: 600\n",
      "X_train (4900, 40)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "# For Banknote, Yeast, Segment, uses 400 test examples\n",
    "# For Abalone, Texture, uses 600 test examples\n",
    "# For htru2, uses 4000 test examples\n",
    "if re.search(r'(banknote)|(yeast)|(segment)', file_path):\n",
    "    N_TEST = 400\n",
    "elif re.search(r'(abalone)|(texture)', file_path):\n",
    "    N_TEST = 600\n",
    "else:\n",
    "    N_TEST = 4000\n",
    "print('n_test:', N_TEST)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=N_TEST)\n",
    "print('X_train', X_train.shape)\n",
    "\n",
    "# Apply scaling\n",
    "xmin, xmax = get_range(X_train)\n",
    "X_train = normalize(X_train, xmin, xmax)\n",
    "X_test = normalize(X_test, xmin, xmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a PyTorch Nueral Network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = PTDataset(X_train, y_train)\n",
    "dataset_test = PTDataset(X_test, y_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "dataloader_test = DataLoader(dataset_test, BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, loss, optimizer, ):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    corrects = 0.\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        l = loss(output, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for display\n",
    "        total_loss += l.item() * batch_size\n",
    "        preds = output.max(1, keepdim=True)[1]\n",
    "        corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, loss):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    corrects = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            output = model(x)\n",
    "            l = loss(output, y)\n",
    "            total_loss += l.item() * batch_size\n",
    "            preds = output.max(1, keepdim=True)[1]\n",
    "            corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_features*4)\n",
    "        self.fc2 = nn.Linear(n_features*4, n_features*4)\n",
    "        self.fc3 = nn.Linear(n_features*4, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Banknote dataset works better on SGD\n",
    "if re.search('banknote', file_path):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1] 0m 0.1s Train Loss: 2.3970 Accuracy: 9.2449%, Test Loss: 2.3956 Accuracy: 7.8333%\n",
      "[ 11] 0m 0.1s Train Loss: 2.2230 Accuracy: 27.2653%, Test Loss: 2.2146 Accuracy: 27.3333%\n",
      "[ 21] 0m 0.1s Train Loss: 1.9988 Accuracy: 67.1429%, Test Loss: 1.9791 Accuracy: 71.0000%\n",
      "[ 31] 0m 0.1s Train Loss: 1.8493 Accuracy: 81.5102%, Test Loss: 1.8422 Accuracy: 82.3333%\n",
      "[ 41] 0m 0.1s Train Loss: 1.7859 Accuracy: 83.3469%, Test Loss: 1.7831 Accuracy: 83.8333%\n",
      "[ 51] 0m 0.1s Train Loss: 1.7518 Accuracy: 84.8163%, Test Loss: 1.7507 Accuracy: 85.5000%\n",
      "[ 61] 0m 0.1s Train Loss: 1.7306 Accuracy: 85.4490%, Test Loss: 1.7319 Accuracy: 85.6667%\n",
      "[ 71] 0m 0.1s Train Loss: 1.7155 Accuracy: 86.4082%, Test Loss: 1.7166 Accuracy: 86.5000%\n",
      "[ 81] 0m 0.1s Train Loss: 1.7045 Accuracy: 86.9184%, Test Loss: 1.7051 Accuracy: 86.6667%\n",
      "[ 91] 0m 0.1s Train Loss: 1.6959 Accuracy: 87.3469%, Test Loss: 1.6971 Accuracy: 87.3333%\n",
      "[101] 0m 0.1s Train Loss: 1.6652 Accuracy: 93.3673%, Test Loss: 1.6715 Accuracy: 93.3333%\n",
      "[111] 0m 0.1s Train Loss: 1.6443 Accuracy: 94.2245%, Test Loss: 1.6537 Accuracy: 93.3333%\n",
      "[121] 0m 0.1s Train Loss: 1.6333 Accuracy: 94.5510%, Test Loss: 1.6436 Accuracy: 93.6667%\n",
      "[131] 0m 0.1s Train Loss: 1.6254 Accuracy: 94.8980%, Test Loss: 1.6360 Accuracy: 93.6667%\n",
      "[141] 0m 0.1s Train Loss: 1.6193 Accuracy: 95.1633%, Test Loss: 1.6293 Accuracy: 93.6667%\n",
      "[151] 0m 0.1s Train Loss: 1.6135 Accuracy: 95.5918%, Test Loss: 1.6249 Accuracy: 94.0000%\n",
      "[161] 0m 0.1s Train Loss: 1.6091 Accuracy: 95.7347%, Test Loss: 1.6196 Accuracy: 94.5000%\n",
      "[171] 0m 0.1s Train Loss: 1.6053 Accuracy: 95.7347%, Test Loss: 1.6158 Accuracy: 94.3333%\n",
      "[181] 0m 0.1s Train Loss: 1.6017 Accuracy: 96.1020%, Test Loss: 1.6121 Accuracy: 94.5000%\n",
      "[191] 0m 0.1s Train Loss: 1.5989 Accuracy: 96.2041%, Test Loss: 1.6091 Accuracy: 94.8333%\n",
      "[201] 0m 0.1s Train Loss: 1.5958 Accuracy: 96.4694%, Test Loss: 1.6067 Accuracy: 94.6667%\n",
      "[211] 0m 0.1s Train Loss: 1.5935 Accuracy: 96.4490%, Test Loss: 1.6039 Accuracy: 95.3333%\n",
      "[221] 0m 0.1s Train Loss: 1.5913 Accuracy: 96.6531%, Test Loss: 1.6016 Accuracy: 95.0000%\n",
      "[231] 0m 0.1s Train Loss: 1.5886 Accuracy: 96.7959%, Test Loss: 1.5988 Accuracy: 95.5000%\n",
      "[241] 0m 0.1s Train Loss: 1.5869 Accuracy: 96.9388%, Test Loss: 1.5964 Accuracy: 95.8333%\n",
      "[251] 0m 0.1s Train Loss: 1.5848 Accuracy: 97.0612%, Test Loss: 1.5945 Accuracy: 96.0000%\n",
      "[261] 0m 0.1s Train Loss: 1.5832 Accuracy: 97.0816%, Test Loss: 1.5916 Accuracy: 96.6667%\n",
      "[271] 0m 0.1s Train Loss: 1.5813 Accuracy: 97.3878%, Test Loss: 1.5897 Accuracy: 96.5000%\n",
      "[281] 0m 0.1s Train Loss: 1.5799 Accuracy: 97.3673%, Test Loss: 1.5879 Accuracy: 96.5000%\n",
      "[291] 0m 0.1s Train Loss: 1.5786 Accuracy: 97.5102%, Test Loss: 1.5877 Accuracy: 96.3333%\n",
      "[301] 0m 0.1s Train Loss: 1.5774 Accuracy: 97.5510%, Test Loss: 1.5850 Accuracy: 96.3333%\n",
      "[311] 0m 0.1s Train Loss: 1.5762 Accuracy: 97.5714%, Test Loss: 1.5826 Accuracy: 97.0000%\n",
      "[321] 0m 0.1s Train Loss: 1.5747 Accuracy: 97.7551%, Test Loss: 1.5818 Accuracy: 97.0000%\n",
      "[331] 0m 0.1s Train Loss: 1.5737 Accuracy: 97.7959%, Test Loss: 1.5804 Accuracy: 97.1667%\n",
      "[341] 0m 0.1s Train Loss: 1.5725 Accuracy: 97.8776%, Test Loss: 1.5786 Accuracy: 97.3333%\n",
      "[351] 0m 0.1s Train Loss: 1.5715 Accuracy: 98.0612%, Test Loss: 1.5805 Accuracy: 96.3333%\n",
      "[361] 0m 0.1s Train Loss: 1.5707 Accuracy: 98.0000%, Test Loss: 1.5765 Accuracy: 97.3333%\n",
      "[371] 0m 0.1s Train Loss: 1.5698 Accuracy: 98.2041%, Test Loss: 1.5755 Accuracy: 97.3333%\n",
      "[381] 0m 0.1s Train Loss: 1.5687 Accuracy: 98.2449%, Test Loss: 1.5749 Accuracy: 97.3333%\n",
      "[391] 0m 0.1s Train Loss: 1.5682 Accuracy: 98.2653%, Test Loss: 1.5738 Accuracy: 97.5000%\n",
      "Total run time: 0m 27.2s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    tr_loss, tr_acc = train(model, dataloader_train, loss, optimizer)\n",
    "    va_loss, va_acc = validate(model, dataloader_test, loss)\n",
    "    \n",
    "    time_elapsed = time.time() - start\n",
    "    if epoch % 10 == 0:\n",
    "        print(('[{:3d}] {:.0f}m {:.1f}s Train Loss: {:.4f} Accuracy: {:.4f}%, ' +\n",
    "            'Test Loss: {:.4f} Accuracy: {:.4f}%').format(\n",
    "                epoch+1, time_elapsed // 60, time_elapsed % 60,\n",
    "                tr_loss, tr_acc*100.,\n",
    "                va_loss, va_acc*100.))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Total run time: {:.0f}m {:.1f}s'.format(\n",
    "    time_elapsed // 60,\n",
    "    time_elapsed % 60))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = SVC()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
