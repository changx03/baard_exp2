{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision as tv\n",
    "import torchvision.datasets as datasets\n",
    "from art.attacks.evasion import BasicIterativeMethod, CarliniL2Method, FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, NearestNeighbors\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util import get_correct_examples, dataset2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CPU threads: 24\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "n_threads = os.cpu_count()\n",
    "print('CPU threads: {}'.format(n_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset\n",
    "transforms = tv.transforms.Compose([tv.transforms.ToTensor()])\n",
    "dataset_train = datasets.MNIST(PATH, train=True, download=True, transform=transforms)\n",
    "dataset_test = datasets.MNIST(PATH, train=False, download=True, transform=transforms)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(dataset_train.data.size())\n",
    "print(dataset_test.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train point-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 10\n"
     ]
    }
   ],
   "source": [
    "# Create Neural Network model\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(9216, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model.to(device)\n",
    "print('Number of layers: {}'.format(len(list(model.children()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, loss, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    corrects = 0.\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        l = loss(outputs, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # for display\n",
    "        total_loss += l.item() * batch_size\n",
    "        preds = outputs.max(1, keepdim=True)[1]\n",
    "        corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, loss):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    corrects = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            outputs = model(x)\n",
    "            l = loss(outputs, y)\n",
    "            total_loss += l.item() * batch_size\n",
    "            preds = outputs.max(1, keepdim=True)[1]\n",
    "            corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1] 0m 4.4s Train Loss: 0.4440 Accuracy: 87.4017%, Test Loss: 0.1358 Accuracy: 95.8500%\n",
      "[ 2] 0m 4.4s Train Loss: 0.1181 Accuracy: 96.3983%, Test Loss: 0.0859 Accuracy: 97.3300%\n",
      "[ 3] 0m 4.3s Train Loss: 0.0714 Accuracy: 97.8183%, Test Loss: 0.0584 Accuracy: 98.1500%\n",
      "[ 4] 0m 4.5s Train Loss: 0.0487 Accuracy: 98.4933%, Test Loss: 0.0519 Accuracy: 98.3900%\n",
      "[ 5] 0m 4.4s Train Loss: 0.0376 Accuracy: 98.8233%, Test Loss: 0.0431 Accuracy: 98.7200%\n",
      "Total run time: 0m 22.0s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    tr_loss, tr_acc = train(model, dataloader_train, loss, optimizer)\n",
    "    va_loss, va_acc = validate(model, dataloader_test, loss)\n",
    "    \n",
    "    time_elapsed = time.time() - start\n",
    "    print(('[{:2d}] {:.0f}m {:.1f}s Train Loss: {:.4f} Accuracy: {:.4f}%, ' +\n",
    "        'Test Loss: {:.4f} Accuracy: {:.4f}%').format(\n",
    "            epoch+1, time_elapsed // 60, time_elapsed % 60,\n",
    "            tr_loss, tr_acc*100.,\n",
    "            va_loss, va_acc*100.))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Total run time: {:.0f}m {:.1f}s'.format(\n",
    "    time_elapsed // 60,\n",
    "    time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 60000\n",
      "Accuracy on 59531 filtered training examples: 100.0000%\n",
      "Test set: 10000\n",
      "Accuracy on 9872 filtered test examples: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Training set: {}'.format(len(dataset_train)))\n",
    "tensor_train_X, tensor_train_y = get_correct_examples(model, dataset_train, device=device, return_tensor=True)\n",
    "dataset_train_perfect = TensorDataset(tensor_train_X, tensor_train_y)\n",
    "dataloader_train_perfect = DataLoader(dataset_train_perfect, batch_size=512, shuffle=True)\n",
    "_, acc = validate(model, dataloader_train_perfect, loss)\n",
    "print('Accuracy on {} filtered training examples: {:.4f}%'.format(len(dataloader_train_perfect.dataset), acc*100))\n",
    "\n",
    "print('Test set: {}'.format(len(dataset_test)))\n",
    "tensor_test_X, tensor_test_y = get_correct_examples(model, dataset_test, device=device, return_tensor=True)\n",
    "dataset_test_perfect = TensorDataset(tensor_test_X, tensor_test_y)\n",
    "dataloader_test_perfect = DataLoader(dataset_test_perfect, batch_size=512, shuffle=True)\n",
    "_, acc = validate(model, dataloader_test_perfect, loss)\n",
    "print('Accuracy on {} filtered test examples: {:.4f}%'.format(len(dataloader_test_perfect.dataset), acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ADV = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = PyTorchClassifier(\n",
    "    model=model, \n",
    "    loss=loss, \n",
    "    input_shape=(1, 28, 28), \n",
    "    optimizer=optimizer,\n",
    "    nb_classes=10,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    device_type=device\n",
    ")\n",
    "\n",
    "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "# attack = BasicIterativeMethod(estimator=classifier, eps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for adversarial examples\n",
    "n = len(dataset_test_perfect)\n",
    "indices = torch.randperm(n)[:N_ADV]\n",
    "\n",
    "pt_subset_X = tensor_test_X[indices]  # PyTorch Tensor\n",
    "pt_subset_y = tensor_test_y[indices]\n",
    "\n",
    "subset_X = pt_subset_X.cpu().detach().numpy()\n",
    "subset_y = pt_subset_y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean examples: 100.0000%\n",
      "Model accuracy on adversarial examples: 40.7000%\n"
     ]
    }
   ],
   "source": [
    "# Create adversarial examples\n",
    "subset_pred = np.argmax(classifier.predict(subset_X), axis=1)\n",
    "accuracy = np.sum(subset_pred == subset_y) / float(len(subset_pred))\n",
    "print(\"Model accuracy on clean examples: {:.4f}%\".format(accuracy * 100))\n",
    "\n",
    "# Generate adversarial examples\n",
    "subset_adv = attack.generate(x=subset_X)\n",
    "subset_pred = np.argmax(classifier.predict(subset_adv), axis=1)\n",
    "\n",
    "accuracy = np.sum(subset_pred == subset_y) / float(len(subset_pred))\n",
    "print(\"Model accuracy on adversarial examples: {:.4f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(5000, 784)\n"
     ]
    }
   ],
   "source": [
    "# From PyTorch dataset to Numpy array\n",
    "pt_X_train, pt_y_train = dataset2tensor(dataset_train)\n",
    "X_train = pt_X_train.cpu().detach().numpy()\n",
    "y_train = pt_y_train.cpu().detach().numpy()\n",
    "\n",
    "# Reshape 2D images into 1D vector\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "\n",
    "# Split model training set into training set and validation set\n",
    "X_rc_train, X_rc_val, y_rc_train, y_rc_val = train_test_split(X_train, y_train, test_size=5000)\n",
    "\n",
    "print(X_rc_train.shape)\n",
    "print(X_rc_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RadiusNeighborsClassifier(radius=0.02)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn = RadiusNeighborsClassifier(radius=0.02, weights='uniform', p=2)\n",
    "# rnn.fit(X_rc_train, y_rc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='chebyshev', n_jobs=-1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chebyshev: L-infinity norm\n",
    "# manhattan: L1 norm\n",
    "# euclidean: L2 norm\n",
    "\n",
    "nn = NearestNeighbors(n_jobs=-1, metric='chebyshev')\n",
    "nn.fit(X_rc_train, y_rc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.69803923, 0.79607843, 0.79607844, 0.86666666, 0.87058824,\n",
       "         0.8745098 , 0.89803922, 0.90196078, 0.90196079, 0.90588236,\n",
       "         0.91764706, 0.92941177, 0.93333333, 0.94117647, 0.94117647,\n",
       "         0.94509804, 0.95294118, 0.95686275, 0.96078431, 0.96078431,\n",
       "         0.96470588, 0.96470588, 0.96862745, 0.96862745, 0.96862745,\n",
       "         0.97254902, 0.97254902, 0.97647059, 0.97647059, 0.97647059,\n",
       "         0.97647059, 0.97647059, 0.97647059, 0.97647059, 0.97647059,\n",
       "         0.97647059, 0.97647059, 0.97647059, 0.97647059, 0.97647059,\n",
       "         0.97647059, 0.97647059, 0.97647059, 0.97647059, 0.97647059,\n",
       "         0.97647059, 0.97647059, 0.97647059, 0.97647059, 0.98039216,\n",
       "         0.98039216, 0.98039216, 0.98431373, 0.98431373, 0.98431373,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.99215686,\n",
       "         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686]]),\n",
       " array([[53112, 10361, 49253, 32633,  8703, 24192, 10132,  3159,   424,\n",
       "         39356, 43488, 49370, 24292, 54654, 19409,  3688,  6149,  4946,\n",
       "         38066, 26707, 47223, 12666, 40165, 18531, 37390, 11322, 46087,\n",
       "         34607, 43707, 35856,  6638, 51770, 17436, 20155, 40487,  4815,\n",
       "          4339, 18395, 32695, 47678, 14712, 15297, 16978, 25615, 26899,\n",
       "          9532, 33921, 10357, 41253, 51148, 50357, 43007, 45344, 15289,\n",
       "          2686, 25226, 48245, 52070, 39413, 28801, 38759, 34316, 40880,\n",
       "         32153, 47353, 50637, 50066, 51928, 54796,  2017, 33091, 46983,\n",
       "         18806, 15035, 32573, 33255, 45255, 34191, 35044, 51342,  6997,\n",
       "          9038, 42517, 44987, 17527,  9088, 33252, 50022, 27963, 13689,\n",
       "         14124, 13868, 13151, 12892, 12074, 12075, 12760, 13223, 13886,\n",
       "         12921]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([X_rc_val[0]], n_neighbors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.533333"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(X_rc_train[53112] - X_rc_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.742458"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((X_rc_train[53112] - X_rc_val[0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69803923"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(X_rc_train[53112] - X_rc_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 7\n"
     ]
    }
   ],
   "source": [
    "print(y_rc_train[53112], y_rc_val[0], y_rc_train[12921])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.all(np.abs(X_rc_train - X_rc_val[0]) < 0.3, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_min = X_rc_val[0] - 0.3\n",
    "X_max = X_rc_val[0] + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-393c646df016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_rc_train\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX_rc_train\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mX_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "np.where(np.all(X_rc_train >= X_min and X_rc_train <= X_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([17131, 42756]),)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.all(X_rc_train >= X_min, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.all(X_rc_train <= X_max, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n"
     ]
    }
   ],
   "source": [
    "print(y_rc_train[17131], y_rc_train[42756])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit4ada1bcfcd0f4caa95e946f583001e1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
