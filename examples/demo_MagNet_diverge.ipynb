{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit4ada1bcfcd0f4caa95e946f583001e1b",
   "display_name": "Python 3.6.9 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## MagNet\n",
    "\n",
    "Testing the divergence based detector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/lukec/workspace/baard_exp2/examples',\n",
       " '/home/lukec/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/pythonFiles',\n",
       " '/home/lukec/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/pythonFiles/lib/python',\n",
       " '/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/lukec/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/home/lukec/.local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/lukec/.ipython',\n",
       " '/home/lukec/workspace/baard_exp2/examples',\n",
       " '/home/lukec/workspace/baard_exp2/examples',\n",
       " '..']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sys.path.append('..')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defences.util import (dataset2tensor, get_correct_examples, get_shape,\n",
    "                           merge_and_generate_labels, score)\n",
    "from defences.magnet import (Autoencoder1, Autoencoder2, MagNetDetector,\n",
    "                             MagNetAutoencoderReformer, MagNetOperator)\n",
    "from defences.feature_squeezing import (GaussianSqueezer, MedianSqueezer,\n",
    "                                        DepthSqueezer, FeatureSqueezingTorch)\n",
    "from models.numeric import NumericModel\n",
    "from models.mnist import BaseModel\n",
    "from models.cifar10 import Resnet, Vgg\n",
    "from experiments.util import load_csv\n",
    "from experiments.train_pt import validate, predict\n",
    "from defences.region_based_classifier import RegionBasedClassifier\n",
    "from defences.lid import LidDetector\n",
    "from defences.baard import (ApplicabilityStage, BAARDOperator,\n",
    "                            DecidabilityStage, ReliabilityStage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', 'data')\n",
    "OUTPUT_PATH = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tv.transforms.Compose([tv.transforms.ToTensor()])\n",
    "dataset_train = datasets.MNIST(DATA_PATH, train=True, download=True, transform=transforms)\n",
    "dataset_test = datasets.MNIST(DATA_PATH, train=False, download=True, transform=transforms)\n",
    "loader_train = DataLoader(dataset_train, batch_size=512, shuffle=False)\n",
    "loader_test = DataLoader(dataset_test, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model = BaseModel(use_prob=True).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "pretrained_path = os.path.join('..', OUTPUT_PATH, 'mnist_200.pt')\n",
    "model.load_state_dict(torch.load(pretrained_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on train set: 99.7117%\nAccuracy on test set: 98.5200%\n"
     ]
    }
   ],
   "source": [
    "_, acc_train = validate(model, loader_train, loss, device)\n",
    "_, acc_test = validate(model, loader_test, loss, device)\n",
    "print('Accuracy on train set: {:.4f}%'.format(acc_train*100))\n",
    "print('Accuracy on test set: {:.4f}%'.format(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on 59827 filtered train set: 100.0000%\n",
      "Accuracy on 9852 filtered test set: 100.0000%\n",
      "Accuracy on 2000 benign samples: 100.0000%\n",
      "Accuracy on 2000 adversarial examples: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "ADV = 'mnist_basic_apgd_0.3'\n",
    "\n",
    "tensor_train_X, tensor_train_y = get_correct_examples(\n",
    "    model, dataset_train, device=device, return_tensor=True)\n",
    "dataset_train = TensorDataset(tensor_train_X, tensor_train_y)\n",
    "loader_train = DataLoader(dataset_train, batch_size=512, shuffle=True)\n",
    "_, acc_perfect = validate(model, loader_train, loss, device)\n",
    "print('Accuracy on {} filtered train set: {:.4f}%'.format(\n",
    "    len(dataset_train), acc_perfect*100))\n",
    "\n",
    "tensor_test_X, tensor_test_y = get_correct_examples(\n",
    "    model, dataset_test, device=device, return_tensor=True)\n",
    "dataset_test = TensorDataset(tensor_test_X, tensor_test_y)\n",
    "loader_test = DataLoader(dataset_test, batch_size=512, shuffle=True)\n",
    "_, acc_perfect = validate(model, loader_test, loss, device)\n",
    "print('Accuracy on {} filtered test set: {:.4f}%'.format(\n",
    "    len(dataset_test), acc_perfect*100))\n",
    "\n",
    "# Load pre-trained adversarial examples\n",
    "path_benign = os.path.join('..', OUTPUT_PATH, ADV + '_x.npy')\n",
    "path_adv = os.path.join('..', OUTPUT_PATH, ADV + '_adv.npy')\n",
    "path_y = os.path.join('..', OUTPUT_PATH, ADV + '_y.npy')\n",
    "X_benign = np.load(path_benign)\n",
    "adv = np.load(path_adv)\n",
    "y_true = np.load(path_y)\n",
    "\n",
    "dataset = TensorDataset(torch.from_numpy(X_benign), torch.from_numpy(y_true))\n",
    "loader = DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "_, acc = validate(model, loader, loss, device)\n",
    "print('Accuracy on {} benign samples: {:.4f}%'.format(\n",
    "    len(dataset), acc*100))\n",
    "dataset = TensorDataset(\n",
    "    torch.from_numpy(adv), torch.from_numpy(y_true))\n",
    "loader = DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "_, acc = validate(model, loader, loss, device)\n",
    "print('Accuracy on {} adversarial examples: {:.4f}%'.format(\n",
    "    len(dataset), acc*100))\n",
    "\n",
    "# Do NOT shuffle the indices, so different defences can use the same test set.\n",
    "dataset = TensorDataset(torch.from_numpy(adv))\n",
    "loader = DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "pred_adv = predict(model, loader, device).cpu().detach().numpy()\n",
    "\n",
    "# Find the thresholds using the 2nd half\n",
    "n = len(X_benign) // 2\n",
    "# Merge benign samples and adversarial examples into one set.\n",
    "# This labels indicate a sample is an adversarial example or not.\n",
    "X_val, labels_val = merge_and_generate_labels(\n",
    "    adv[n:], X_benign[n:], flatten=False)\n",
    "# The predictions for benign samples are exactly same as the true labels.\n",
    "pred_val = np.concatenate((pred_adv[n:], y_true[n:]))\n",
    "\n",
    "X_train = tensor_train_X.cpu().detach().numpy()\n",
    "y_train = tensor_train_y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE training set: 0.000063, test set: 0.000063\n"
     ]
    }
   ],
   "source": [
    "magnet_detectors = []\n",
    "magnet_detectors.append(\n",
    "    MagNetDetector(\n",
    "        encoder=Autoencoder2(n_channel=1),\n",
    "        classifier=model,\n",
    "        lr=0.001,\n",
    "        batch_size=256,\n",
    "        weight_decay=1e-9,\n",
    "        x_min=0.0,\n",
    "        x_max=1.0,\n",
    "        noise_strength=0.025,\n",
    "        algorithm='prob',\n",
    "        p=2,\n",
    "        temperature=10,\n",
    "        device=device))\n",
    "ENCODER_PATH = os.path.join('..', OUTPUT_PATH, 'autoencoder_mnist_2.pt')\n",
    "magnet_detectors[0].load(ENCODER_PATH)\n",
    "\n",
    "tensor_X_test, _ = dataset2tensor(dataset_test)\n",
    "X_test = tensor_X_test.cpu().detach().numpy()\n",
    "print('MSE training set: {:.6f}, test set: {:.6f}'.format(\n",
    "    magnet_detectors[0].score(X_train), \n",
    "    magnet_detectors[0].score(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformer = MagNetAutoencoderReformer(\n",
    "    encoder=magnet_detectors[0].encoder,\n",
    "    batch_size=256,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MagNetOperator(\n",
    "    classifier=model,\n",
    "    detectors=magnet_detectors,\n",
    "    reformer=reformer,\n",
    "    batch_size=256,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, labels_test = merge_and_generate_labels(\n",
    "    adv[:n], X_benign[:n], flatten=False)\n",
    "pred_test = np.concatenate((pred_adv[:n], y_true[:n]))\n",
    "y_test = np.concatenate((y_true[:n], y_true[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9995"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "detector.score(X_test, m, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}